---
title: "Results Analysis"
author: "Laila Johnston"
date: '2025-02-25'
output: html_document
---

```{r}
# Needed libraries 
library(dplyr)
library(ggplot2)
library(ggrepel)
library(patchwork)
library(plotly)
library(readr)
library(tidyr)
library(tidytext)
library(tidyverse)
library(viridis)
```

# Word Stats 
```{r}
uncleaned_data_net <- read_csv("~/laila_johnston@brown.edu - Google Drive/Shared drives/BLT Lab/Current Studies/SCA (Structure of Computational Alternatives; formerly CompAlt and RSA)/Extensions (Laila)/data/wordNet_top_words.csv")
uncleaned_data_vec <- read_csv("~/laila_johnston@brown.edu - Google Drive/Shared drives/BLT Lab/Current Studies/SCA (Structure of Computational Alternatives; formerly CompAlt and RSA)/Extensions (Laila)/data/word2Vec_top_words.csv")

df_bert = read_csv("~/laila_johnston@brown.edu - Google Drive/Shared drives/BLT Lab/Current Studies/SCA (Structure of Computational Alternatives; formerly CompAlt and RSA)/Extensions (Laila)/data/BERT_top_words.csv")

udf_net <- as.data.frame(uncleaned_data_net)
df_vec <- as.data.frame(uncleaned_data_vec)
min_score_net <- min(uncleaned_data_net$resnik_score)
max_score_net <- max(uncleaned_data_net$resnik_score)
min_score_vec <- min(uncleaned_data_vec$cosine_similarity)
max_score_vec <- max(uncleaned_data_vec$cosine_similarity)
df_net <- subset(udf_net, resnik_score < max_score_net) # because we have some values that are 1e+300
max_score_net <- max(df_net$resnik_score)
```

```{r}
df_vec_new = df_vec %>% 
  mutate(model = "Word2Vec") %>% 
  rename(score = cosine_similarity) %>% 
  group_by(context) %>%
  top_n(15, score)

df_net_new = df_net %>% 
  mutate(model = "WordNet") %>% 
  rename(score = resnik_score) %>% 
  group_by(context) %>%
  top_n(15, score)

combined_df <- rbind(df_vec_new, df_net_new)
```


```{r}
# Filter the top 10 tokens for each context based on probability
top_words <- df_bert %>%
  group_by(context) %>%
  top_n(15, probability) %>%
  arrange(context, desc(probability)) %>% 
  mutate(token = factor(token, levels = unique(token)))

ggplot(top_words, aes(x = token, y = probability, fill = context)) +
  geom_bar(stat = "identity") +
  geom_text(aes(label = round(probability, 3)), vjust = -0.5, size = 2) +
  facet_wrap(~context, scales = "free_x") +
  labs(title = "BERT Top 10 Words by Context",
       x = "Words",
       y = "Probability Score") +
  ylim(0, 1) +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
```


```{r}
#wordNet subsets
bag_net <- subset(df_net, context == "bag")
bakery_net <- subset(df_net, context == "bakery")
beach_net <- subset(df_net, context == "beach")
cold_net <- subset(df_net, context == "cold")
cut_net <- subset(df_net, context == "cut")
fridge_net <- subset(df_net, context == "fridge")
gym_net <- subset(df_net, context == "gym")
hot_net <- subset(df_net, context == "hot")
mask_net <- subset(df_net, context == "mask")
meat_net <- subset(df_net, context == "meat")
restaurant_net <- subset(df_net, context == "restaurant")
salad_net <- subset(df_net, context == "salad")
science_net <- subset(df_net, context == "science")
throw_net <- subset(df_net, context == "throw")
transport_net <- subset(df_net, context == "transport")

#word2Vec subsets
bag_vec <- subset(df_vec, context == "bag")
bakery_vec <- subset(df_vec, context == "bakery")
beach_vec <- subset(df_vec, context == "beach")
cold_vec <- subset(df_vec, context == "cold")
cut_vec <- subset(df_vec, context == "cut")
fridge_vec <- subset(df_vec, context == "fridge")
gym_vec <- subset(df_vec, context == "gym")
hot_vec <- subset(df_vec, context == "hot")
mask_vec <- subset(df_vec, context == "mask")
meat_vec <- subset(df_vec, context == "meat")
restaurant_vec <- subset(df_vec, context == "restaurant")
salad_vec <- subset(df_vec, context == "salad")
science_vec <- subset(df_vec, context == "science")
throw_vec <- subset(df_vec, context == "throw")
transport_vec <- subset(df_vec, context == "transport")
```


```{r}
# NOTE: we get top 10, but the top_n function in dplyr includes if there are ties (which there are) so that's why sometimes there are more than 10
# input: string value of the trigger: "bag", "bakery", ...etc
make_graph <- function(input) {
  net <- subset(df_net, context == input)
  vec <- subset(df_vec, context == input)
  
  # Normalize the scores
  net$normalized_score <- (net$resnik_score - min_score_net) / (max_score_net - min_score_net) * 100
  vec$normalized_score <- (vec$cosine_similarity - min_score_vec) / (max_score_vec - min_score_vec) * 100
  
  # Select top 10 for each trigger
  net10 <- net %>% group_by(trigger) %>% top_n(10, normalized_score) %>% ungroup()
  vec10 <- vec %>% group_by(trigger) %>% top_n(10, normalized_score) %>% ungroup()
  
  # Label datasets
  net10$dataset <- "net"
  vec10$dataset <- "vec"
  
  # Combine and factorize
  combined10 <- bind_rows(net10, vec10)
  combined10$dataset <- factor(combined10$dataset, levels = c("net", "vec"))
  
  # Order labels
  labels <- unique(net$trigger)[order(unique(net$trigger))]
  
  # Create the plotly object
  p <- ggplot(combined10, aes(x = trigger, y = normalized_score, color = dataset, 
                              text = paste("Word: ", word))) +
    geom_jitter(width = 0.1, height = 0, size = 2, alpha = 0.7) +
    scale_x_discrete(labels = labels) +
    labs(x = "Trigger", y = "Normalized Score", title = paste(input, ": Top 10 Words by Trigger")) +
    theme_minimal() +
    theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
    scale_color_manual(values = c("net" = "blue", "vec" = "red"))
  
  # Convert to plotly with custom tooltip
  ggplotly(p, tooltip = "text")
}

# List of contexts
contexts <- c("bag", "bakery", "beach", "cold", "cut", "fridge", 
              "gym", "hot", "mask", "meat", "restaurant", 
              "salad", "science", "throw", "transport")

# Generate all plots
plots <- lapply(contexts, make_graph)

plots

# # Combine all plots into a single figure
# combined_plot = subplot(plots, nrows = 4, margin = 0.05, shareX = FALSE, shareY = TRUE, titleX = FALSE, titleY = TRUE)
# 
# # Add titles manually as annotations for each subplot
# annotations <- lapply(seq_along(contexts), function(i) {
#   list(
#     x = (i - 1) %% 4 / 4 + 0.125,
#     y = 1 - (floor((i - 1) / 4) / 4),
#     text = contexts[i],
#     xref = "paper",
#     yref = "paper",
#     showarrow = FALSE,
#     font = list(size = 12, color = "black")
#   )
# })
# 
# # Apply annotations to the combined plot
# combined_plot <- combined_plot %>% layout(annotations = annotations)
# 
# # Display the final plot
# combined_plot
# 
# # make_graph("bag")
```

```{r}
# bag
bag_net$normalized_score <- (bag_net$resnik_score - min_score_net) / (max_score_net - min_score_net) * 100
bag10 <- bag_net %>% group_by(trigger) %>% top_n(10, normalized_score) %>% ungroup()
bag_plot <- ggplotly(ggplot(bag10, aes(x = trigger, y = normalized_score, text = paste("Word: ", word))) +
                       geom_jitter(width = 0.1, height = 0, size = 2, alpha = 0.7) +
                       scale_x_discrete(labels = c("cash", "chalk", "crayons", "headphones", "makeup", "pen")) +
                       labs(x = "Trigger", y = "Normalized Score", title = "Bag: Top 10 Scores by Trigger") +
                       theme_minimal() +
                       theme(axis.text.x = element_text(angle = 45, hjust = 1)), tooltop="text")
bag_plot
```


```{r}
# bakery
bakery_net$normalized_score <- (bakery_net$resnik_score - min_score_net) / (max_score_net - min_score_net) * 100
bakery10 <- bakery_net %>% group_by(trigger) %>% top_n(10, normalized_score) %>% ungroup()
bakery_plot <- ggplotly(ggplot(bakery10, aes(x = trigger, y = normalized_score, text = paste("Word: ", word))) +
                       geom_jitter(width = 0.1, height = 0, size = 2, alpha = 0.7) +
                       scale_x_discrete(labels = c("cakes", "sandwiches", "muffins", "pretzels", "water")) +
                       labs(x = "Trigger", y = "Normalized Score", title = "Bakery: Top 10 Scores by Trigger") +
                       theme_minimal() +
                       theme(axis.text.x = element_text(angle = 45, hjust = 1)), tooltop="text")
bakery_plot
```






# Results (Context only: "I only have [MASK]")

```{r}
# Import result files 
set_results = read_csv("~/laila_johnston@brown.edu - Google Drive/Shared drives/BLT Lab/Current Studies/SCA (Structure of Computational Alternatives; formerly CompAlt and RSA)/Extensions (Laila)/results/set_results_july2025.csv",
                      col_types = cols(
                        context = col_character(),
                        trigger = col_character(),
                        query = col_character(),
                        empirical_probability = col_double(), 
                        log_likelihood = col_double()
              )) %>%
              rename(
                cleaned_trigger = trigger,
                cleaned_query   = query
              )

ordering_results <- read_csv("~/laila_johnston@brown.edu - Google Drive/Shared drives/BLT Lab/Current Studies/SCA (Structure of Computational Alternatives; formerly CompAlt and RSA)/Extensions (Laila)/results/ordering_results_july2025.csv",
                      col_types = cols(
                        context = col_character(),
                        trigger = col_character(),
                        query = col_character(),
                        empirical_probability = col_double(), 
                        log_likelihood = col_double()
              )) %>%
              rename(
                cleaned_trigger = trigger,
                cleaned_query   = query
              )

conjunction_results <- read_csv("~/laila_johnston@brown.edu - Google Drive/Shared drives/BLT Lab/Current Studies/SCA (Structure of Computational Alternatives; formerly CompAlt and RSA)/Extensions (Laila)/results/conjunction_results_july2025.csv",
                      col_types = cols(
                        context = col_character(),
                        trigger = col_character(),
                        query = col_character(),
                        empirical_probability = col_double(), 
                        log_likelihood = col_double()
              )) %>%
              rename(
                cleaned_trigger = trigger,
                cleaned_query   = query
              )

disjunction_results <- read_csv("~/laila_johnston@brown.edu - Google Drive/Shared drives/BLT Lab/Current Studies/SCA (Structure of Computational Alternatives; formerly CompAlt and RSA)/Extensions (Laila)/results/disjunction_results_july2025.csv",
                      col_types = cols(
                        context = col_character(),
                        trigger = col_character(),
                        query = col_character(),
                        empirical_probability = col_double(), 
                        log_likelihood = col_double()
              )) %>%
              rename(
                cleaned_trigger = trigger,
                cleaned_query   = query
              )

always_negate_results = read_csv("~/laila_johnston@brown.edu - Google Drive/Shared drives/BLT Lab/Current Studies/SCA (Structure of Computational Alternatives; formerly CompAlt and RSA)/Extensions (Laila)/results/always_negate_results_july2025.csv",
                      col_types = cols(
                        context = col_character(),
                        trigger = col_character(),
                        query = col_character(),
                        empirical_probability = col_double(), 
                        log_likelihood = col_double()
              )) %>%
              rename(
                cleaned_trigger = trigger,
                cleaned_query   = query
              )

never_negate_results = read_csv("~/laila_johnston@brown.edu - Google Drive/Shared drives/BLT Lab/Current Studies/SCA (Structure of Computational Alternatives; formerly CompAlt and RSA)/Extensions (Laila)/results/never_negate_results_july2025.csv",
                      col_types = cols(
                        context = col_character(),
                        trigger = col_character(),
                        query = col_character(),
                        empirical_probability = col_double(), 
                        log_likelihood = col_double()
              )) %>%
              rename(
                cleaned_trigger = trigger,
                cleaned_query   = query
              )

sca_data = read_csv("~/laila_johnston@brown.edu - Google Drive/Shared drives/BLT Lab/Current Studies/SCA (Structure of Computational Alternatives; formerly CompAlt and RSA)/Extensions (Laila)/data/sca_dataframe.csv",
                    col_types = cols(
                      story             = col_character(),
                      cleaned_trigger   = col_character(),
                      trigger_relevance = col_double(),
                      cleaned_query     = col_character(),
                      query_relevance   = col_double() 
                    )) %>% 
                    rename(
                      context = story
                    )

queries_not_in_distribution = read_csv("~/laila_johnston@brown.edu - Google Drive/Shared drives/BLT Lab/Current Studies/SCA (Structure of Computational Alternatives; formerly CompAlt and RSA)/Extensions (Laila)/results/queries_not_in_distribution_july2025.csv")

# df <- read_csv(disjunction_results, col_types = cols(
#   context        = col_character(),
#   trigger        = col_character(),
#   query          = col_character(),
#   empirical_probability    = col_double()
# )) %>%
#   rename(
#     cleaned_trigger = trigger,
#     cleaned_query   = query
#   )

# sca_data <- read_csv(sca_data, col_types = cols(
#   story             = col_character(),
#   cleaned_trigger   = col_character(),
#   trigger_relevance = col_double(),
#   cleaned_query     = col_character(),
#   query_relevance   = col_double()
# ))

```



# Print context name, number of cells missing, number of critical cells missing, log likelihood for total cells, log likelihood for critical cells.
```{r}
# 1) Build a one-row-per-key lookup from SCA
region_lookup <- sca_data %>%
  filter(!is.na(region)) %>%
  count(context, cleaned_trigger, cleaned_query, region, name = "n") %>%
  arrange(context, cleaned_trigger, cleaned_query, desc(n)) %>%
  group_by(context, cleaned_trigger, cleaned_query) %>%
  slice_head(n = 1) %>%           # pick the most frequent region per key
  ungroup() %>%
  select(context, cleaned_trigger, cleaned_query, region)

# 2) Left-join to add `region` (preserves row count)
set_results <- set_results %>%
  left_join(region_lookup,
            by = c("context" = "context", "cleaned_trigger" = "cleaned_trigger", "cleaned_query" = "cleaned_query"))

results_df <- set_results %>%
  group_by(context) %>%
  summarise(
    average_log_likelihood = mean(log_likelihood, na.rm = TRUE),

    average_log_likelihood_critical_regions =
      if (any(region %in% c("A", "D"), na.rm = TRUE)) {
        mean(log_likelihood[region %in% c("A", "D")], na.rm = TRUE)
      } else {
        NA_real_
      },

    # unique (trigger, query) pairs per context
    total_cells = n_distinct(paste(cleaned_trigger, cleaned_query, sep = "__")),

    # unique (trigger, query) pairs in critical regions A & D
    num_critical_region_cells =
      n_distinct(paste(cleaned_trigger[region %in% c("A", "D")],
                       cleaned_query[region %in% c("A", "D")], sep = "__")),
    .groups = "drop"
  ) %>%
  mutate(
    missing_cells = 30 - total_cells,
    missing_cells_critical_region = 6 - num_critical_region_cells
  )

results_df

```

# Model sanity checks: Is region A mor negated than region C?, etc.
```{r}

# Average empirical probability by region
region_summary <- set_results %>%
  group_by(region) %>%
  summarise(
    avg_empirical_probability = mean(empirical_probability, na.rm = TRUE),
    .groups = "drop"
  )

region_summary

# Average empirical probability by region and context
region_context_summary <- set_results %>%
  group_by(context, region) %>%
  summarise(
    avg_empirical_probability = mean(empirical_probability, na.rm = TRUE)
    .groups = "drop"
  )

region_context_summary


```


# Aggregate at the top level (average everything, which model has the best log likelihood)
```{r}
# Put your dataframes into a named list
model_list <- list(
  Set             = set_results,
  Ordering        = ordering_results,
  Conjunction     = conjunction_results,
  Disjunction     = disjunction_results,
  Always_Negate   = always_negate_results,
  Never_Negate    = never_negate_results
)

# Summarize mean and SE of log_likelihood for each model
summary_df <- lapply(names(model_list), function(model_name) {
  df <- model_list[[model_name]]
  x  <- df$log_likelihood
  x  <- x[!is.na(x)]
  n  <- length(x)
  data.frame(
    model = model_name,
    mean_log_likelihood = if (n > 0) mean(x) else NA_real_,
    se_log_likelihood   = if (n > 1) sd(x) / sqrt(n) else NA_real_
  )
}) %>%
  bind_rows()

# Desired x-axis order
model_order <- c("Set", "Ordering", "Disjunction", "Conjunction", "Always_Negate", "Never_Negate")
summary_df$model <- factor(summary_df$model, levels = model_order)

# Plot (uses SE for error bars, fixed model order on x-axis)
p <- ggplot(summary_df, aes(x = model, y = mean_log_likelihood)) +
  geom_point(size = 5, color = "steelblue") +
  geom_errorbar(aes(ymin = mean_log_likelihood - se_log_likelihood,
                    ymax = mean_log_likelihood + se_log_likelihood),
                width = 0.2) +
  geom_text(aes(label = round(mean_log_likelihood, 2)),
            nudge_x = 0.15, size = 3.7, hjust = 0) +
  ylim(-25, 5) +
  labs(
    title = "Mean Log Likelihood by Model (Average Everything)",
    x = "Model",
    y = "Mean Log Likelihood"
  )

ggsave("~/laila_johnston@brown.edu - Google Drive/Shared drives/BLT Lab/Current Studies/SCA (Structure of Computational Alternatives; formerly CompAlt and RSA)/Extensions (Laila)/figures/mean_log_likelihood_by_model_average_everything.png", plot = p, width = 8, height = 6, dpi = 300)

print(p)

```

# Aggregate at the top level (average by context then average that, which model has the best log likelihood)
```{r}
# Step 1: Get mean log_likelihood per context for each model
context_means_df <- lapply(names(model_list), function(model_name) {
  model_list[[model_name]] %>%
    group_by(context) %>%
    summarise(mean_log_likelihood = mean(log_likelihood, na.rm = TRUE), .groups = "drop") %>%
    mutate(model = model_name)
}) %>%
  bind_rows()

# Step 2: Summarize mean and SE across contexts per model
summary_by_context_df <- context_means_df %>%
  group_by(model) %>%
  summarise(
    total_mean_log_likelihood = mean(mean_log_likelihood, na.rm = TRUE),
    n_contexts = sum(!is.na(mean_log_likelihood)),
    se_log_likelihood = if (n_contexts > 1) sd(mean_log_likelihood, na.rm = TRUE) / sqrt(n_contexts) else NA_real_,
    .groups = "drop"
  )

# Desired x-axis order
model_order <- c("Set", "Ordering", "Disjunction", "Conjunction", "Always_Negate", "Never_Negate")
summary_by_context_df$model <- factor(summary_by_context_df$model, levels = model_order)

# Step 3: Plot (uses SE for error bars, fixed model order)
p <- ggplot(summary_by_context_df, aes(x = model, y = total_mean_log_likelihood)) +
  geom_point(size = 4, color = "darkorange") +
  geom_errorbar(aes(ymin = total_mean_log_likelihood - se_log_likelihood,
                    ymax = total_mean_log_likelihood + se_log_likelihood),
                width = 0.2) +
  geom_text(aes(label = round(total_mean_log_likelihood, 2)),
            nudge_x = 0.2, hjust = 0, size = 3.5) +
  ylim(-25, 5) +
  labs(
    title = "Avg Log Likelihood by Model\n(first average by context, then overall mean)",
    x = "Model",
    y = "Mean Log Likelihood (Averaged by Context)")

ggsave("~/laila_johnston@brown.edu - Google Drive/Shared drives/BLT Lab/Current Studies/SCA (Structure of Computational Alternatives; formerly CompAlt and RSA)/Extensions (Laila)/figures/mean_log_likelihood_by_model_average_context_prompt_with_article.png", plot = p, width = 8, height = 6, dpi = 300)

print(p)
```



# Aggregate at the context level 
```{r}
high_contrast_colors <- c(
  "#e41a1c",  # red
  "#377eb8",  # blue
  "#4daf4a",  # green
  "#984ea3",  # purple
  "#ff7f00",  # orange
  "#ffff33",  # yellow
  "#a65628",  # brown
  "#f781bf",  # pink
  "#999999",  # gray
  "#66c2a5",  # turquoise
  "#fc8d62",  # salmon
  "#8da0cb",  # steel blue
  "#e78ac3",  # light pink
  "#a6d854",  # lime green
  "#ffd92f",  # bright yellow
  "#e5c494"   # tan
)

model_order <- c("Disjunction", "Ordering", "Set", "Conjunction", "Always_Negate", "Never_Negate")

context_level_df <- lapply(names(model_list), function(model_name) {
  model_list[[model_name]] %>%
    group_by(context) %>%
    summarise(mean_log_likelihood = mean(log_likelihood, na.rm = TRUE), .groups = "drop") %>%
    mutate(model = model_name)
}) %>%
  bind_rows() %>%
  mutate(model = factor(model, levels = model_order))

context_level_df$context <- factor(context_level_df$context)

# Plot: one dot per context-model pair
p = ggplot(context_level_df, aes(x = model, y = mean_log_likelihood)) +
  geom_point(aes(color = context), 
             position = position_jitter(width = 0.35), 
             alpha = 0.85, 
             size = 4) +
  scale_color_manual(values = high_contrast_colors) +
  labs(
    title = "Mean Log Likelihood by Context for Each Model\nPrompt with Article",
    x = "Model",
    y = "Mean Log Likelihood (per Context)"
  ) 

ggsave("~/laila_johnston@brown.edu - Google Drive/Shared drives/BLT Lab/Current Studies/SCA (Structure of Computational Alternatives; formerly CompAlt and RSA)/Extensions (Laila)/figures/mean_log_likelihood_by_context_prompt_with_article.png", plot = p, width = 12, height = 6, dpi = 500)

print(p)
```

```{r}

high_contrast_colors <- c(
  "#e41a1c",  # red
  "#377eb8",  # blue
  "#4daf4a",  # green
  "#984ea3",  # purple
  "#ff7f00",  # orange
  "#ffff33"   # yellow
)

model_order <- c("Disjunction", "Ordering", "Set", "Conjunction", "Always_Negate", "Never_Negate")

# Create dataframe: mean log likelihood per context for each model
context_level_df <- lapply(names(model_list), function(model_name) {
  model_list[[model_name]] %>%
    group_by(context) %>%
    summarise(mean_log_likelihood = mean(log_likelihood, na.rm = TRUE), .groups = "drop") %>%
    mutate(model = model_name)
}) %>%
  bind_rows() %>%
  mutate(model = factor(model, levels = model_order),
         context = factor(context))  # keep context order fixed if needed

# Which models to use for the ordering criterion
target_models <- c("Disjunction", "Ordering", "Set", "Conjunction")

# Order contexts by descending (max - min) mean log-likelihood across the four target models
context_order <- context_level_df %>%
  filter(model %in% target_models) %>%
  group_by(context) %>%
  summarise(spread = max(mean_log_likelihood, na.rm = TRUE) -
                    min(mean_log_likelihood, na.rm = TRUE),
            .groups = "drop") %>%
  arrange(desc(spread)) %>%
  pull(context) %>%
  as.character()

# Apply the new order to the plotting data
context_level_df <- context_level_df %>%
  mutate(context = factor(context, levels = context_order))

# Plot: context on x-axis, model colors as dots
p <- ggplot(context_level_df, aes(x = context, y = mean_log_likelihood, color = model)) +
  geom_point(position = position_dodge(width = 0.6), size = 4, alpha = 0.85) +
  scale_color_manual(values = high_contrast_colors, name = "Model") +
  labs(
    title = "Mean Log Likelihood by Model for Each Context\nPrompt with article\nFake Data - Always Negate",
    x = "Context",
    y = "Mean Log Likelihood"
  ) 

ggsave("~/laila_johnston@brown.edu - Google Drive/Shared drives/BLT Lab/Current Studies/SCA (Structure of Computational Alternatives; formerly CompAlt and RSA)/Extensions (Laila)/figures/mean_log_likelihood_by_context_with_article_fake_data_always_negate.png", plot = p, width = 12, height = 6, dpi = 500)

print(p)

```

# scatter plot of probabilities to find outliers 

```{r}
# Bind all model results into one dataset with a "model" column
all_models <- bind_rows(
  set_results        %>% mutate(model = "Set"),
  ordering_results   %>% mutate(model = "Ordering"),
  conjunction_results %>% mutate(model = "Conjunction"),
  disjunction_results %>% mutate(model = "Disjunction")
)

# Average empirical probability by context, trigger/query, and model
model_avg <- all_models %>%
  group_by(context, cleaned_trigger, cleaned_query, model) %>%
  summarise(avg_empirical = mean(empirical_probability, na.rm = TRUE), .groups = "drop")

# Average human probability (from sca_data$neg)
human_avg <- sca_data %>%
  group_by(context, cleaned_trigger, cleaned_query) %>%
  summarise(avg_human = mean(neg, na.rm = TRUE), .groups = "drop")

# Merge model predictions with human data
plot_data <- model_avg %>%
  left_join(human_avg, by = c("context", "cleaned_trigger", "cleaned_query")) %>%
  mutate(pair_label = paste(cleaned_trigger, "/", cleaned_query))

# Scatter plot

plot_data$model <- factor(plot_data$model, 
                          levels = c("Set", "Disjunction", "Ordering", "Conjunction"))

p = ggplot(plot_data %>% filter(context == "hot"),
       aes(x = avg_empirical, y = avg_human)) +
  geom_point(aes(color = model), size = 4) +
  geom_text_repel(aes(label = pair_label), 
                  size = 4.5, 
                  max.overlaps = Inf, 
                  show.legend = FALSE) +
  facet_wrap(~model, ncol = 2) +
  labs(
    title = "Models vs Human Negation Probability for trigger / query pairs\nHot Context",
    x = "Average Model Negation Probability",
    y = "Average Human Negation Probability"
  )

print(p)

ggsave("~/laila_johnston@brown.edu - Google Drive/Shared drives/BLT Lab/Current Studies/SCA (Structure of Computational Alternatives; formerly CompAlt and RSA)/Extensions (Laila)/figures/scatter_probabilities_hot.png", plot = p, width = 14, height = 9, dpi = 400)



```


# specific context only: grid plots 

```{r}
# Keep only these triggers/queries
keep <- c("chalk", "cash", "makeup", "pen")

specific_context_df <- sca_data %>%
  filter(context == "bag",
         cleaned_trigger %in% keep,
         cleaned_query   %in% keep) %>%
  group_by(cleaned_trigger, cleaned_query) %>%
  summarise(
    mean_neg          = mean(neg, na.rm = TRUE),
    sd_neg            = sd(neg, na.rm = TRUE),
    trigger_relevance = mean(trigger_relevance, na.rm = TRUE),
    query_relevance   = mean(query_relevance,   na.rm = TRUE),
    .groups = "drop"
  ) %>%
  mutate(
    trigger_ord = reorder_within(cleaned_trigger,  trigger_relevance, within = "bag"),
    query_ord   = reorder_within(cleaned_query,   trigger_relevance,  within = "bag"),
    label = sprintf("%.2f\n(%.2f)", mean_neg, sd_neg)
  )

p = ggplot(specific_context_df, aes(x = trigger_ord, y = query_ord, fill = mean_neg)) +
  geom_tile(color = "white") +
  geom_text(aes(label = label), size = 3) +
  scale_fill_gradient(low = "green", high = "red", limits = c(0, 1), name = "Avg neg") +
  scale_x_reordered() +
  scale_y_reordered() +
  labs(
    title = "Bag — Average Human Negation",
    x = "Trigger (ordered by relevance)",
    y = "Query (ordered by relevance)"
  ) +
  coord_equal() +
  # theme_minimal(base_size = 12) +
  theme(
    axis.text.x = element_text(angle = 45, hjust = 1),
    panel.grid  = element_blank()
  )

ggsave("~/laila_johnston@brown.edu - Google Drive/Shared drives/BLT Lab/Current Studies/SCA (Structure of Computational Alternatives; formerly CompAlt and RSA)/Extensions (Laila)/figures/bag_human_negation.png", plot = p, width = 12, height = 6, dpi = 500)

print(p)


```

```{r}
# Pull relevance once from sca_data (dedupe)
relevance <- sca_data %>%
  select(context, cleaned_trigger, trigger_relevance,
         cleaned_query) %>%
  distinct()

specific_context_df <- disjunction_results %>%
  filter(context == "bag",
         cleaned_trigger %in% keep,
         cleaned_query   %in% keep) %>%
  # bring in trigger/query relevance from sca_data
  left_join(relevance,
            by = c("context" = "context",
                   "cleaned_trigger" = "cleaned_trigger",
                   "cleaned_query"   = "cleaned_query")) %>%
  group_by(cleaned_trigger, cleaned_query) %>%
  summarise(
    mean_val          = mean(empirical_probability, na.rm = TRUE),
    sd_val            = sd(empirical_probability,   na.rm = TRUE),
    trigger_relevance = mean(trigger_relevance,     na.rm = TRUE),
    query_relevance   = mean(trigger_relevance,     na.rm = TRUE),
    .groups = "drop"
  ) %>%
  mutate(
    trigger_ord = reorder_within(cleaned_trigger,  trigger_relevance, within = "bag"),
    query_ord   = reorder_within(cleaned_query,   trigger_relevance,  within = "bag"),
    label = sprintf("%.2f\n(%.2f)", mean_val, sd_val)
  )

p = ggplot(specific_context_df, aes(x = trigger_ord, y = query_ord, fill = mean_val)) +
  geom_tile(color = "white") +
  geom_text(aes(label = label), size = 3) +
  scale_fill_gradient(low = "green", high = "red", limits = c(0, 1), name = "Negation Prob") +
  scale_x_reordered() +
  scale_y_reordered() +
  labs(
    title = "Bag - Average Negation Probability - Disjunction Model - Prompt with article",
    x = "Trigger (ordered by relevance)",
    y = "Query (ordered by relevance)"
  ) +
  coord_equal() +
  # theme_minimal(base_size = 12) +
  theme(
    axis.text.x = element_text(angle = 45, hjust = 1),
    panel.grid  = element_blank()
  )

ggsave("~/laila_johnston@brown.edu - Google Drive/Shared drives/BLT Lab/Current Studies/SCA (Structure of Computational Alternatives; formerly CompAlt and RSA)/Extensions (Laila)/figures/bag_disjunction_negation_article.png", plot = p, width = 12, height = 6, dpi = 500)

print(p)
```

# Set Boundary plots 

```{r}
# Set boundary vs average log likleihood for each model 

# 1) Put only the four models into a list
model_list <- list(
  Set         = set_results,
  Ordering    = ordering_results,
  Conjunction = conjunction_results,
  Disjunction = disjunction_results
)

# 2) Bind + keep only what we need
all_models <- lapply(names(model_list), function(m) {
  model_list[[m]] %>%
    select(set_boundary, log_likelihood) %>%
    mutate(model = m)
}) %>% bind_rows()

# Optional: ensure legend order you prefer
model_order <- c("Set", "Ordering", "Disjunction", "Conjunction")
all_models$model <- factor(all_models$model, levels = model_order)

# 3) Average per (model, set_boundary)
summary_sb <- all_models %>%
  group_by(model, set_boundary) %>%
  summarise(
    mean_ll = mean(log_likelihood, na.rm = TRUE),
    n       = sum(!is.na(log_likelihood)),
    se_ll   = if (n > 1) sd(log_likelihood, na.rm = TRUE) / sqrt(n) else NA_real_,
    .groups = "drop"
  )

# 4) Plot: one panel, colored by model
p = ggplot(summary_sb, aes(x = set_boundary, y = mean_ll, color = model, group = model)) +
  geom_line(size = 1) +
  geom_point(size = 2.5) +
  # If you want SE error bars, uncomment the next lines:
  geom_errorbar(aes(ymin = mean_ll - se_ll, ymax = mean_ll + se_ll), width = 0.1, alpha = 0.6) +
  labs(
    title = "Average Log Likelihood by Set Boundary for Each Model",
    x = "Set Boundary",
    y = "Mean Log Likelihood") 

ggsave("~/laila_johnston@brown.edu - Google Drive/Shared drives/BLT Lab/Current Studies/SCA (Structure of Computational Alternatives; formerly CompAlt and RSA)/Extensions (Laila)/figures/set_boundary_by_model.png", plot = p, width = 12, height = 6, dpi = 500)

print(p)


```

```{r}
# set boundary by model and context 

high_contrast_colors <- c(
  "#e41a1c",  # red
  "#377eb8",  # blue
  "#4daf4a",  # green
  "#984ea3",  # purple
  "#ff7f00",  # orange
  "#ffff33",  # yellow
  "#a65628",  # brown
  "#f781bf",  # pink
  "#999999",  # gray
  "#66c2a5",  # turquoise
  "#fc8d62",  # salmon
  "#8da0cb",  # steel blue
  "#e78ac3",  # light pink
  "#a6d854",  # lime green
  "#ffd92f",  # bright yellow
  "#e5c494"   # tan
)

# Bind and keep needed columns
all_models <- lapply(names(model_list), function(m) {
  model_list[[m]] %>%
    select(context, set_boundary, log_likelihood) %>%
    mutate(model = m)
}) %>% bind_rows()

# Ensure facet order
model_order <- c("Set", "Ordering", "Disjunction", "Conjunction")
all_models$model <- factor(all_models$model, levels = model_order)

# Summarize mean (and SE if you want error bars)
summary_sb <- all_models %>%
  group_by(model, context, set_boundary) %>%
  summarise(
    mean_ll = mean(log_likelihood, na.rm = TRUE),
    n       = sum(!is.na(log_likelihood)),
    se_ll   = if (n > 1) sd(log_likelihood, na.rm = TRUE) / sqrt(n) else NA_real_,
    .groups = "drop"
  )

# Plot: one facet per model; lines/points colored by context
p = ggplot(summary_sb,
       aes(x = set_boundary, y = mean_ll, color = context, group = context)) +
  geom_line(size = 0.5) +
  geom_point(size = 1.5) +
  # Optional error bars (uncomment to show SE):
  # geom_errorbar(aes(ymin = mean_ll - se_ll, ymax = mean_ll + se_ll),
  #               width = 0.1, alpha = 0.6) +
  facet_wrap(~model, ncol = 2) +
  scale_color_manual(values = high_contrast_colors) +
  labs(
    title = "Average Log Likelihood by Set Boundary and Context",
    x = "Set Boundary",
    y = "Mean Log Likelihood",
    color = "Context"
  )

ggsave("~/laila_johnston@brown.edu - Google Drive/Shared drives/BLT Lab/Current Studies/SCA (Structure of Computational Alternatives; formerly CompAlt and RSA)/Extensions (Laila)/figures/set_boundary_by_model_by_context.png", plot = p, width = 12, height = 8, dpi = 500)

print(p)


```




```{r}
neg_plot_df <- sca_data %>%
  group_by(story, cleaned_trigger, cleaned_query) %>%
  summarise(value = mean(neg, na.rm = TRUE), .groups = "drop") %>%
  rename(context = story) %>%
  mutate(
    plot_type = "Human Negation",
    sd = NA
  )

get_model_df <- function(df, context_col, type_name, value_col) {
  df %>%
    group_by({{ context_col }}, cleaned_trigger, cleaned_query) %>%
    summarise(
      value = mean({{ value_col }}, na.rm = TRUE),
      sd = sd({{ value_col }}, na.rm = TRUE),
      .groups = "drop"
    ) %>%
    rename(context = {{ context_col }}) %>%
    mutate(plot_type = type_name)
}

# 12 plots
plot_dfs <- list(
  neg_plot_df,
  get_model_df(set_results, context, "Set Log Likelihood", log_likelihood),
  get_model_df(set_results, context, "Set Empirical Probability", empirical_probability),
  get_model_df(ordering_results, context, "Ordering Log Likelihood", log_likelihood),
  get_model_df(ordering_results, context, "Ordering Empirical Probability", empirical_probability),
  get_model_df(conjunction_results, context, "Conjunction Log Likelihood", log_likelihood),
  get_model_df(conjunction_results, context, "Conjunction Empirical Probability", empirical_probability),
  get_model_df(disjunction_results, context, "Disjunction Log Likelihood", log_likelihood),
  get_model_df(disjunction_results, context, "Disjunction Empirical Probability", empirical_probability),
  get_model_df(always_negate_results, context, "Always Negate Log Likelihood", log_likelihood),
  get_model_df(always_negate_results, context, "Always Negate Empirical Probability", empirical_probability),
  get_model_df(never_negate_results, context, "Never Negate Log Likelihood", log_likelihood),
  get_model_df(never_negate_results, context, "Never Negate Empirical Probability", empirical_probability)
)

# Combine all into one dataframe
full_plot_df <- bind_rows(plot_dfs)
```


```{r}
make_tile_plot <- function(df, title = NULL) {
  # Decide color scale
  if (grepl("Empirical Probability|Human Negation", title)) {
    fill_scale <- scale_fill_gradient(low = "green", high = "red", limits = c(0, 1), name = "")
  } else {
    fill_scale <- scale_fill_gradientn(colours = c("red", "blue", "green"), name = "")
  }

  # Create formatted label with mean and sd
  df <- df %>%
    mutate(label = ifelse(is.na(sd),
                          sprintf("%.2f", value),
                          sprintf("%.2f\n(%.2f)", value, sd)))

  ggplot(df, aes(x = cleaned_trigger, y = cleaned_query, fill = value)) +
    geom_tile(color = "white") +
    geom_text(aes(label = label), size = 2.5) +
    fill_scale +
    theme_minimal(base_size = 9) +
    labs(
      title = title,
      x = "Trigger",
      y = "Query"
    ) +
    theme(
      axis.text.x = element_text(angle = 45, hjust = 1),
      panel.grid = element_blank(),
      plot.title = element_text(size = 10, face = "bold", hjust = 0.5)
    )
}

contexts <- unique(full_plot_df$context)

for (ctx in contexts) {
  context_df <- filter(full_plot_df, context == ctx)

  # Get a list of 13 plots in the desired order
  plot_order <- c(
    "Human Negation",
    "Set Log Likelihood", "Set Empirical Probability",
    "Ordering Log Likelihood", "Ordering Empirical Probability",
    "Conjunction Log Likelihood", "Conjunction Empirical Probability",
    "Disjunction Log Likelihood", "Disjunction Empirical Probability",
    "Always Negate Log Likelihood", "Always Negate Empirical Probability",
    "Never Negate Log Likelihood", "Never Negate Empirical Probability"
  )

  plots <- lapply(plot_order, function(ptype) {
    df_sub <- filter(context_df, plot_type == ptype)
    make_tile_plot(df_sub, ptype)
  })

  # Combine into 3x5 grid (13 plots — will fill row by row)
  full_plot <- wrap_plots(plots, ncol = 3)

  # Save
  ggsave(
    filename = paste0("~/laila_johnston@brown.edu - Google Drive/Shared drives/BLT Lab/Current Studies/SCA (Structure of Computational Alternatives; formerly CompAlt and RSA)/Extensions (Laila)/figures/context_", gsub("[^a-zA-Z0-9]", "_", ctx), ".png"),
    plot = full_plot,
    width = 14, height = 12, dpi = 300
  )
}

```













# Grip Plots for Likelihood 

```{r}
# 2) Compute the average empirical probability per (context, trigger, query)
avg_df <- never_negate_results %>%
  group_by(context, cleaned_trigger, cleaned_query) %>%
  summarise(
    mean_likelihood = mean(log_likelihood, na.rm = TRUE),
    sd_likelihood = sd(log_likelihood, na.rm = TRUE),
    .groups = "drop"
  )

# 4) Merge in the relevance scores
plot_df <- avg_df %>%
  # bring in trigger_relevance
  left_join(
    sca_data %>% select(story, cleaned_trigger, trigger_relevance) %>% distinct(),
    by = c("context" = "story", "cleaned_trigger")
  ) %>%
  # bring in query_relevance
  left_join(
    sca_data %>% select(story, cleaned_query, query_relevance) %>% distinct(),
    by = c("context" = "story", "cleaned_query")
  )

plot_df <- plot_df %>%
  mutate(
    trigger_ord = reorder_within(cleaned_trigger,
                                trigger_relevance,
                                context,
                                fun = mean),
    query_ord   = reorder_within(cleaned_query,
                                -query_relevance,
                                context,
                                fun = mean)
  )

# 6) Plot with facet_wrap and the green→red fill
p <- ggplot(plot_df,
            aes(x = trigger_ord,
                y = query_ord,
                fill = mean_likelihood)) +
  geom_tile(color = "white") +
  # add text labels, rounded to two decimals
  geom_text(aes(label = sprintf("%.2f\n(%.2f)", mean_likelihood, sd_likelihood)),
          size = 2, color = "black") +
  scale_fill_gradientn(
    colours = c("red", "blue", "green"),
    name = "Avg Log Likelihood") +
  facet_wrap(~ context, scales = "free") +
  scale_x_reordered() +
  scale_y_reordered() +
  theme_minimal(base_size = 10) +
  labs(
    title = "Average Log Likelihood by Context\nNever Negate Model\nPrompt: 'I only have [MASK]'",
    x     = "Trigger (0→5 left→right)",
    y     = "Query   (0→5 top→bottom)"
  ) +
  theme(
    axis.text.x = element_text(angle = 45, hjust = 1),
    panel.grid  = element_blank(),
    strip.text  = element_text(size = 12)
  )

print(p)

# 7) Save to file
# ggsave(
#   filename = OUTPUT_PNG,
#   plot     = p,
#   width    = 12,
#   height   = 8,
#   dpi      = 300
# )

# after you’ve built p
ggsave(
  filename = "~/laila_johnston@brown.edu - Google Drive/Shared drives/BLT Lab/Current Studies/SCA (Structure of Computational Alternatives; formerly CompAlt and RSA)/Extensions (Laila)/figures/log_likelihood_never_negate.png",
  plot     = p,
  width    = 12,
  height   = 10,
  dpi      = 300,
  bg = "white"
)
```

# Grid Plots for Human data 
```{r}
# Filter for fridge context
context_df <- sca_data %>%
  filter(story == "fridge") %>%
  group_by(cleaned_trigger, cleaned_query) %>%
  summarise(
    mean_neg = mean(neg, na.rm = TRUE),
    sd_neg = sd(neg, na.rm = TRUE),
    trigger_relevance = mean(trigger_relevance, na.rm = TRUE),
    query_relevance = mean(query_relevance, na.rm = TRUE),
    .groups = "drop"
  ) %>%
  mutate(
    trigger_ord = reorder_within(cleaned_trigger, trigger_relevance, group = 1),
    query_ord = reorder_within(cleaned_query, query_relevance, group = 1),
    label = ifelse(is.na(sd_neg),
                   sprintf("%.2f", mean_neg),
                   sprintf("%.2f\n(%.2f)", mean_neg, sd_neg))
  )

# Plot
ggplot(fridge_df, aes(x = trigger_ord, y = query_ord, fill = mean_neg)) +
  geom_tile(color = "white") +
  geom_text(aes(label = label), size = 3) +
  scale_fill_gradient(low = "green", high = "red", limits = c(0, 1), name = "Mean Neg") +
  scale_x_reordered() +
  scale_y_reordered() +
  labs(
    title = "Fridge Context — Mean Human Negation",
    x = "Trigger (ordered by relevance)",
    y = "Query (ordered by relevance)"
  ) +
  theme_minimal(base_size = 11) +
  theme(
    axis.text.x = element_text(angle = 45, hjust = 1),
    panel.grid = element_blank()
  )


print(p)

# ggsave(
#   filename = "~/laila_johnston@brown.edu - Google Drive/Shared drives/BLT Lab/Current Studies/SCA (Structure of Computational Alternatives; formerly CompAlt and RSA)/Extensions (Laila)/figures/negation_probability_participant_data_fridge.png",
#   plot     = p,
#   width    = 12,
#   height   = 8,
#   dpi      = 300,
#   bg = "white"
# )
```


# Grid Plots for Empirical Probability
```{r}

# 2) Compute the average empirical probability per (context, trigger, query)
avg_df <- set_results %>%
  group_by(context, cleaned_trigger, cleaned_query) %>%
  summarise(
    mean_empirical = mean(empirical_probability, na.rm = TRUE),
    sd_empiricial = sd(empirical_probability, na.rm = TRUE),
    .groups = "drop")

# 4) Merge in the relevance scores
plot_df <- avg_df %>%
  # bring in trigger_relevance
  left_join(
    sca_data %>% select(story, cleaned_trigger, trigger_relevance) %>% distinct(),
    by = c("context" = "story", "cleaned_trigger")
  ) %>%
  # bring in query_relevance
  left_join(
    sca_data %>% select(story, cleaned_query, query_relevance) %>% distinct(),
    by = c("context" = "story", "cleaned_query")
  )

plot_df <- plot_df %>%
  mutate(
    trigger_ord = reorder_within(cleaned_trigger,
                                trigger_relevance,
                                context,
                                fun = mean),
    query_ord   = reorder_within(cleaned_query,
                                query_relevance,
                                context,
                                fun = mean)
  ) %>% 
  filter(context == "fridge")

# 6) Plot with facet_wrap and the green→red fill
p <- ggplot(plot_df,
            aes(x = trigger_ord,
                y = query_ord,
                fill = mean_empirical)) +
  geom_tile(color = "white") +
  # add text labels, rounded to two decimals
  geom_text(aes(label = sprintf("%.2f\n(%.2f)", mean_empirical, sd_empiricial)),
          size = 6, color = "black") +
  scale_fill_gradient(low = "green", high = "red",
                      name = "Avg Neg Prob") +
  facet_wrap(~ context, scales = "free") +
  scale_x_reordered() +
  scale_y_reordered() +
  theme_minimal(base_size = 14) +
  labs(
    title = "Average Negation Probability\nContext: Fridge\nSet Model",
    x     = "Trigger (0→5)",
    y     = "Query   (0→5)"
  ) +
  theme(
    axis.text.x = element_text(angle = 45, hjust = 1),
    panel.grid  = element_blank(),
    strip.text  = element_text(size = 12)
  )

print(p)

# after you’ve built p
ggsave(
  filename = "~/laila_johnston@brown.edu - Google Drive/Shared drives/BLT Lab/Current Studies/SCA (Structure of Computational Alternatives; formerly CompAlt and RSA)/Extensions (Laila)/figures/negation_probability_set_fridge.png",
  plot     = p,
  width    = 12,
  height   = 8,
  dpi      = 300,
  bg = "white"
)
```


```{r}
# Add a model column and combine the dataframes 

set_results$model <- "Set"
ordering_results$model <- "Ordering"
conjunction_results$model <- "Conjunction"
disjunction_results$model <- "Disjunction"
always_negate_results$model = "Always Negate"
never_negate_results$model = "Never Negate"

df_results <- bind_rows(set_results, ordering_results, conjunction_results, disjunction_results, always_negate_results, never_negate_results)

# Compute the mean of the log_likelihoods and the standard error of the log_likelihoods for each set_boundary and model
summary_df <- df_results %>%
  group_by(set_boundary, model) %>%
  summarise(
    mean_log_likelihood = mean(log_likelihood, na.rm = TRUE),
    se_log_likelihood = sd(log_likelihood, na.rm = TRUE) / sqrt(n()))

# Plot of the mean log_likelihoods as a function of set boundary (four lines, one for each model) with standard error of the mean
ggplot(summary_df, aes(x = set_boundary, y = mean_log_likelihood, color = model)) +
  geom_line() +
  geom_point() +
  geom_errorbar(aes(ymin = mean_log_likelihood - se_log_likelihood, ymax = mean_log_likelihood + se_log_likelihood), width = 0.2) +
  labs(x = "Set Boundary", y = "Log Likelihood", title = "Mean of log likelihoods  as a function of set boundary with standard error of the mean\nAveraged accross all contexts and trials") +
  theme_minimal() +
  theme(legend.title = element_blank())
```

```{r}
context_df_set <- set_results %>%
  group_by(set_boundary, context) %>%
  summarise(
    mean_log_likelihood = mean(log_likelihood, na.rm = TRUE),
    se_log_likelihood = sd(log_likelihood, na.rm = TRUE) / sqrt(n()))

ggplot(context_df_set, aes(x = set_boundary, y = mean_log_likelihood, color = context)) +
  geom_line() +
  geom_point() +
  # geom_errorbar(aes(ymin = mean_log_likelihood - se_log_likelihood, ymax = mean_log_likelihood + se_log_likelihood), width = 0.2) +
  labs(x = "Set Boundary", y = "Log Likelihood", title = "Set Model\nMean of log likelihoodsas a function of set boundary\nAveraged accross triggers and queries") +
  theme_minimal() +
  theme(legend.title = element_blank())
```

```{r}
context_df_ordering <- ordering_results %>%
  group_by(set_boundary, context) %>%
  summarise(
    mean_log_likelihood = mean(log_likelihood, na.rm = TRUE),
    se_log_likelihood = sd(log_likelihood, na.rm = TRUE) / sqrt(n()))

ggplot(context_df_ordering, aes(x = set_boundary, y = mean_log_likelihood, color = context)) +
  geom_line() +
  geom_point() +
  # geom_errorbar(aes(ymin = mean_log_likelihood - se_log_likelihood, ymax = mean_log_likelihood + se_log_likelihood), width = 0.2) +
  labs(x = "Set Boundary", y = "Log Likelihood", title = "Ordering Model\nMean of log likelihoods as a function of set boundary\nAveraged accross triggers and queries") +
  theme_minimal() +
  theme(legend.title = element_blank())
```

```{r}
context_df_con <- conjunction_results %>%
  group_by(set_boundary, context) %>%
  summarise(
    mean_log_likelihood = mean(log_likelihood, na.rm = TRUE),
    se_log_likelihood = sd(log_likelihood, na.rm = TRUE) / sqrt(n()))

ggplot(context_df_con, aes(x = set_boundary, y = mean_log_likelihood, color = context)) +
  geom_line() +
  geom_point() +
  # geom_errorbar(aes(ymin = mean_log_likelihood - se_log_likelihood, ymax = mean_log_likelihood + se_log_likelihood), width = 0.2) +
  labs(x = "Set Boundary", y = "Log Likelihood", title = "Conjunction Model\nMean of log likelihoods as a function of set boundary\nAveraged accross triggers and queries") +
  theme_minimal() +
  theme(legend.title = element_blank())
```


```{r}
context_df_dis <- disjunction_results %>%
  group_by(set_boundary, context) %>%
  summarise(
    mean_log_likelihood = mean(log_likelihood, na.rm = TRUE),
    se_log_likelihood = sd(log_likelihood, na.rm = TRUE) / sqrt(n()))

ggplot(context_df_dis, aes(x = set_boundary, y = mean_log_likelihood, color = context)) +
  geom_line() +
  geom_point() +
  # geom_errorbar(aes(ymin = mean_log_likelihood - se_log_likelihood, ymax = mean_log_likelihood + se_log_likelihood), width = 0.2) +
  labs(x = "Set Boundary", y = "Log Likelihood", title = "Disjunction Model\nMean of log likelihoods as a function of set boundary\nAveraged accross triggers and queries") +
  theme_minimal() +
  theme(legend.title = element_blank())
```


```{r}
context_df <- ordering_results %>%
  filter(context == "fridge") %>% 
  group_by(set_boundary, trigger) %>%
  summarise(
    mean_log_likelihood = mean(log_likelihood, na.rm = TRUE),
    se_log_likelihood = sd(log_likelihood, na.rm = TRUE) / sqrt(n()))

ggplot(context_df, aes(x = set_boundary, y = mean_log_likelihood, color = trigger)) +
  geom_line() +
  geom_point() +
  # geom_errorbar(aes(ymin = mean_log_likelihood - se_log_likelihood, ymax = mean_log_likelihood + se_log_likelihood), width = 0.2) +
  labs(x = "Set Boundary", y = "Log Likelihood", title = "Set Model, Context 'hot'\nMean of log likelihoods as a function of set boundary\nAveraged accross queries") +
  theme_minimal() +
  theme(legend.title = element_blank())
```
# Results (Context and trigger: "I only have {trigger} and [MASK]")

```{r}
# Import result files 
set_results_trigger = read_csv("~/laila_johnston@brown.edu - Google Drive/Shared drives/BLT Lab/Current Studies/SCA (Structure of Computational Alternatives; formerly CompAlt and RSA)/Extensions (Laila)/results/set_with_trigger_AND_results.csv")

ordering_results_trigger <- read_csv("~/laila_johnston@brown.edu - Google Drive/Shared drives/BLT Lab/Current Studies/SCA (Structure of Computational Alternatives; formerly CompAlt and RSA)/Extensions (Laila)/results/ordering_with_trigger_AND_results.csv")

conjunction_results_trigger <- read_csv("~/laila_johnston@brown.edu - Google Drive/Shared drives/BLT Lab/Current Studies/SCA (Structure of Computational Alternatives; formerly CompAlt and RSA)/Extensions (Laila)/results/conjunction_with_trigger_AND_results.csv")

disjunction_results_trigger <- read_csv("~/laila_johnston@brown.edu - Google Drive/Shared drives/BLT Lab/Current Studies/SCA (Structure of Computational Alternatives; formerly CompAlt and RSA)/Extensions (Laila)/results/disjunction_with_trigger_AND_results.csv")
```
```{r}
# Add a model column and combine the dataframes 
set_results_trigger$model <- "Set"
ordering_results_trigger$model <- "Ordering"
conjunction_results_trigger$model <- "Conjunction"
disjunction_results_trigger$model <- "Disjunction"
df_results_trigger <- bind_rows(set_results_trigger, ordering_results_trigger, conjunction_results_trigger, disjunction_results_trigger)

# Compute the mean of the log_likelihoods and the standard error of the log_likelihoods for each set_boundary and model
summary_df_trigger <- df_results_trigger %>%
  group_by(set_boundary, model) %>%
  summarise(
    mean_log_likelihood = mean(log_likelihood, na.rm = TRUE),
    se_log_likelihood = sd(log_likelihood, na.rm = TRUE) / sqrt(n()))

# Plot of the mean log_likelihoods as a function of set boundary (four lines, one for each model) with standard error of the mean
ggplot(summary_df_trigger, aes(x = set_boundary, y = mean_log_likelihood, color = model)) +
  geom_line() +
  geom_point() +
  geom_errorbar(aes(ymin = mean_log_likelihood - se_log_likelihood, ymax = mean_log_likelihood + se_log_likelihood), width = 0.2) +
  labs(x = "Set Boundary", y = "Log Likelihood", title = "Mean of log likelihoods  as a function of set boundary with standard error of the mean\nAveraged accross all contexts and trials\nPrompt: 'I only have {trigger} and [MASK]'") +
  theme_minimal() +
  theme(legend.title = element_blank())
```

```{r}
context_df_ordering_trigger <- ordering_results_trigger %>%
  group_by(set_boundary, context) %>%
  summarise(
    mean_log_likelihood = mean(log_likelihood, na.rm = TRUE),
    se_log_likelihood = sd(log_likelihood, na.rm = TRUE) / sqrt(n()))

ggplot(context_df_ordering_trigger, aes(x = set_boundary, y = mean_log_likelihood, color = context)) +
  geom_line() +
  geom_point() +
  # geom_errorbar(aes(ymin = mean_log_likelihood - se_log_likelihood, ymax = mean_log_likelihood + se_log_likelihood), width = 0.2) +
  labs(x = "Set Boundary", y = "Log Likelihood", title = "Ordering Model\nMean of log likelihoods as a function of set boundary\nAveraged accross triggers and queries\nPrompt: 'I only have {trigger} and [MASK]'") +
  theme_minimal() +
  theme(legend.title = element_blank())
```

```{r}
context_df <- ordering_results_trigger %>%
  filter(context == "fridge") %>% 
  group_by(set_boundary, trigger) %>%
  summarise(
    mean_log_likelihood = mean(log_likelihood, na.rm = TRUE),
    se_log_likelihood = sd(log_likelihood, na.rm = TRUE) / sqrt(n()))

ggplot(context_df, aes(x = set_boundary, y = mean_log_likelihood, color = trigger)) +
  geom_line() +
  geom_point() +
  # geom_errorbar(aes(ymin = mean_log_likelihood - se_log_likelihood, ymax = mean_log_likelihood + se_log_likelihood), width = 0.2) +
  labs(x = "Set Boundary", y = "Log Likelihood", title = "Ordering Model, Context 'fridge'\nMean of log likelihoods as a function of set boundary\nAveraged accross queries\nPrompt: 'I only have {trigger} and [MASK]") +
  theme_minimal() +
  theme(legend.title = element_blank())
```



